# Answer Generator

The Answer Generator reads a set of documents and generates an answer to a question, word by word.
While extractive QA highlights the span of text that answers a query,
generative QA can return a novel text answer that it has composed.
The best current approaches can draw upon both the knowledge it gained during language model pretraining (parametric memory)
and the passages provided to it with a Retriever (non-parametric memory).

Haystack offers generative systems that can be run on your own hardware
such as [Retriever-Augmented Generation](https://arxiv.org/abs/2005.11401) and [LFQA](https://yjernite.github.io/lfqa.html),
With the advent of transformer-based retrieval methods such as [Dense Passage Retrieval](https://arxiv.org/abs/2004.04906),
Answer Generators can be trained concurrently with the Retriever from the one loss signal.

With Haystack, you also have the option of offloading answer generation to an API.
[GPT-3](https://openai.com/api/) from OpenAI is a large scale generative language model that can be used in this question answering setting.
It is infeasible to run a model of this size on local hardware, but you can query an instance of GPT-3 via an API.
The `OpenAIAnswerGenerator` class facilitates this, and it functions just like any other Node in Haystack.
Note that to use GPT-3, you will need a valid OpenAI account and API key.

|||
|-------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|__Position in a Pipeline__| After the Retriever, you can use it as a substitute to the Reader. |
|__Input__       | [Documents](/components/documents-answers-labels#document)                                                                                                                                                                   |
|__Output__      | [Answers](/components/documents-answers-labels#answer)                                                                                                                                                                     |
|__Classes__     | RAGenerator, Seq2SeqGenerator, OpenAIAnswerGenerator                                                                                                                                        |
|||


**Pros**

- More appropriately phrased answers.
- Able to synthesize information from different texts.
- Can draw on latent knowledge stored in language model.

**Cons**

- Not easy to track what piece of information the Answer Generator is basing its response off of.

<div className="max-w-xl bg-yellow-light-theme border-l-8 border-yellow-dark-theme px-6 pt-6 pb-4 my-4 rounded-md dark:bg-yellow-900">

**Tutorial:** Build your own generative QA system with [RAG](/tutorials/retrieval-augmented-generation)
and [LFQA](/tutorials/lfqa).

</div>

## Answer Generator Classes

* `RAGenerator`: [Retrieval-Augmented Generator](https://arxiv.org/abs/2005.11401) based on Hugging Face's [transformers model](https://huggingface.co/transformers/model_doc/rag.html). Its main advantages are a manageable model size and the fact that the answer generation depends on retrieved documents. This means that the model can easily adjust to domain documents even after the training is finished.
* `Seq2SeqGenerator`: A generic sequence-to-sequence generator based on Hugging Face's transformers. You can use it with any Hugging Face language model that extends [GenerationMixin](https://huggingface.co/transformers/main_classes/model.html?transformers.generation_utils.GenerationMixin#transformers.generation_utils.GenerationMixin). See also [How to Generate Text](https://huggingface.co/blog/how-to-generate).
* `OpenAIAnswerGenerator`: A class that calls the GPT-3 model hosted by OpenAI. It performs queries by making API calls but otherwise functions like any other Haystack Node.

## Usage

To initialize a locally hosted Answer Generator, run:

``` python
from haystack.nodes import RAGenerator

generator = RAGenerator(
    model_name_or_path="facebook/rag-sequence-nq",
    retriever=dpr_retriever,
    top_k=1,
    min_length=2
)
```

To initialize the `OpenAIAnswerGenerator`, run:

``` python
from haystack.nodes import OpenAIAnswerGenerator

generator = OpenAIAnswerGenerator(api_key=MY_API_KEY)
```

To run an Answer Generator in a pipeline, run:

``` python
from haystack.pipelines import GenerativeQAPipeline

pipeline = GenerativeQAPipeline(generator=generator, retriever=retriever)
result = pipelines.run(query='What are the best party games for adults?', params={"Retriever": {"top_k": 5}})
```

To run a stand-alone Answer Generator, run:

``` python
result = generator.predict(
    query='What are the best party games for adults?',
    documents=[doc1, doc2, doc3...],
    top_k=top_k
)
```
