# Query Classifier

Classifying queries lets you route them to specific branches of your pipeline that are better suited to handling them, giving you better search results.
The QueryClassifier populates the metadata fields of the query with the classification label and can also handle the routing.

For example, it can be used to route keyword queries to a less-computationally expensive sparse Retriever, while passing questions to a dense Retriever, thus saving you time and GPU resources.
Alternatively, queries can also be categorized by topic and routed to the appropriate database.

|||
|-------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|__Position in a Pipeline__| At the beginning of a query Pipeline |
|__Input__       | Query                                                                                                                                                                  |
|__Output__      | Query                                                                                                                                                                    |
|__Classes__     | TransformersQueryClassifier<br />SklearnQueryClassifier                                                                                                                                             |
|||

## Usage

You can use the QueryClassifier as a stand-alone node in which case it returns two objects: the query and the name of the output edge. To do so, run:

```python
from haystack.nodes import TransformersQueryClassifier

queries = ["Arya Stark father","Jon Snow UK",
           "who is the father of arya stark?","Which country was jon snow filmed in?"]

question_classifier = TransformersQueryClassifier(model_name_or_path="shahrukhx01/bert-mini-finetune-question-detection")
# Or Sklearn based:

for query in queries:
    result = question_classifier.run(query=query)
    if result[1] == "output_1":
        category = "question"
    else:
        category = "keywords"

    print(f"Query: {query}, raw_output: {result}, class: {category}")

# Returns:
# Query: Arya Stark father, raw_output: ({'query': 'Arya Stark father'}, 'output_2'), class: keywords
# Query: Jon Snow UK, raw_output: ({'query': 'Jon Snow UK'}, 'output_2'), class: keywords
# Query: who is the father of arya stark?, raw_output: ({'query': 'who is the father of arya stark?'}, 'output_1'), class: question
# Query: Which country was jon snow filmed in?, raw_output: ({'query': 'Which country was jon snow filmed in?'}, 'output_1'), class: question
```

To use the QueryClassifier within a pipeline as a [decision node](/pipeline_nodes/overview#decision-nodes), run:

```python
from haystack import Pipeline
from haystack.nodes import TransformersQueryClassifier
from haystack.utils import print_answers

query_classifier = TransformersQueryClassifier(model_name_or_path="shahrukhx01/bert-mini-finetune-question-detection")

pipe = Pipeline()
pipe.add_node(component=query_classifier, name="QueryClassifier", inputs=["Query"])
pipe.add_node(component=dpr_retriever, name="DensePassageRetriever", inputs=["QueryClassifier.output_1"])
pipe.add_node(component=bm25_retriever, name="BM25Retriever", inputs=["QueryClassifier.output_2"])

# Pass a question -> run DPR
res_1 = pipe.run(query="Who is the father of Arya Stark?")

# Pass keywords -> run the BM25Retriever
res_2 = pipe.run(query="arya stark father")
```

Here, the query is processed by only one branch of the pipeline, depending on the output of the QueryClassifier.

## Classifying Keyword, Question and Statement Queries

<Disclosures
    options={[
        {
            title: "Keyword Queries",
            content: (
                <div>

                Keyword queries don't have sentence structure. They consist of keywords and the order of words does not matter. For example:

                <ul style=“list-style-type:disc”>

                <li>arya stark father</li>

                <li>jon snow country</li>

                <li>arya stark younger brothers</li>

                </ul>

                </div>
            )
        },
    ]}
/>

XXXXXXXX ADD DEFINITIONS HERE

One recommended setup would be to route both questions and statements to a DensePassageRetriever, which is better accustomed to these types, while routing keyword queries to an ElasticsearchRetriever in order to save GPU resources.
To learn about these different query types, see [Query Type Definitions](/pipeline_nodes/query-classifier#query-type-definitions).

![image](https://user-images.githubusercontent.com/6007894/127831511-f55bad86-4b4f-4b54-9889-7bba37e475c6.png)

A code example of this configuration is shown in [Usage](/pipeline_nodes/query-classifier#usage).
This pipeline has a `TransformersQueryClassifier` that routes questions and statements to the node's `output_1` and keyword queries to `output_2`.
The DensePassageRetriever to `QueryClassifier.output_1` and the ESRetriever to `QueryClassifier.output_2`.

An alternative setup is to route questions to a question answering branch and keywords to a document search branch:

```python
haystack.pipeline import TransformersQueryClassifier, Pipeline
from haystack.utils import print_answers

query_classifier = TransformersQueryClassifier(model_name_or_path="shahrukhx01/question-vs-statement-classifier")

pipe = Pipeline()
pipe.add_node(component=query_classifier, name="QueryClassifier", inputs=["Query"])
pipe.add_node(component=dpr_retriever, name="DPRRetriever", inputs=["QueryClassifier.output_1"])
pipe.add_node(component=bm25_retriever, name="BM25", inputs=["QueryClassifier.output_2"])
pipe.add_node(component=reader, name="QAReader", inputs=["DPRRetriever"])

# Pass a question -> run DPR + QA -> return answers
res_1 = pipe.run(query="Who is the father of Arya Stark?")

# Pass keywords -> run only BM25Retriever -> return Documents
res_2 = pipe.run(query="arya stark father")
```

### Models

To perform this classification of keywords, questions and statements, you can use either the TransformersQueryClassifier or SkLearnQueryClassifier.
The TransformersQueryClassifier is more accurate than the SkLearnQueryClassifier as it is sensitive to the syntax of a sentence.
However, it requires more memory and a GPU in order to run quickly.
You can mitigate those downsides by choosing a smaller transformer model.
The default model used in the TransformerQueryClassifier is `shahrukhx01/bert-mini-finetune-question-detection`.
We trained this using a mini BERT architecture which is about `50 MB` in size and allows relatively fast inference on CPU.

XXXX COLLAPSE

#### Transformers

Pass your own `Transformer` binary classification model from file or use one of the following pretrained models hosted on Hugging Face:

**Keywords vs. Questions/Statements (Default)**

   ```python
   TransformersQueryClassifier(model_name_or_path="shahrukhx01/bert-mini-finetune-question-detection")
   # output_1 => question/statement
   # output_2 => keyword query
   ```

Learn more about this model from its [model card](https://huggingface.co/shahrukhx01/bert-mini-finetune-question-detection).

**Questions vs. Statements**

    ```python
    TransformersQueryClassifier(model_name_or_path="shahrukhx01/question-vs-statement-classifier")
    # output_1 => question
    # output_2 => statement
    ```

Learn more about this model from its [model card](https://huggingface.co/shahrukhx01/question-vs-statement-classifier).

#### Sklearn

Pass your own `Sklearn` binary classification model or use one of the following pretrained gradient boosting models:

**Keywords vs. Questions/Statements (Default)**

    ```python
    SklearnQueryClassifier(query_classifier = "https://ext-models-haystack.s3.eu-central-1.amazonaws.com/gradboost_query_classifier/model.pickle",
                      query_vectorizer = "https://ext-models-haystack.s3.eu-central-1.amazonaws.com/gradboost_query_classifier/vectorizer.pickle")

    # output_1 => question/statement
    # output_2 => keyword query
    ```
Learn more about this model from its [readme](https://ext-models-haystack.s3.eu-central-1.amazonaws.com/gradboost_query_classifier/readme.txt).

**Questions vs. Statements**

    ```python
    SklearnQueryClassifier(query_classifier = "https://ext-models-haystack.s3.eu-central-1.amazonaws.com/gradboost_query_classifier_statements/model.pickle",
                      query_vectorizer = "https://ext-models-haystack.s3.eu-central-1.amazonaws.com/gradboost_query_classifier_statements/vectorizer.pickle")

    output_1 => question
    output_2 => statement
    ```
Learn more about this model from its [readme](https://ext-models-haystack.s3.eu-central-1.amazonaws.com/gradboost_query_classifier_statements/readme.txt).

## Zero-Shot Classification

While most classification models, like those shown in the examples above, have a predefined set of labels, zero-shot classification models can perform classification with any set of labels that you define.
To initialize a zero-shot QueryClassifier, run:

```python
 # In zero-shot-classification, you can choose the labels
 labels = ["music", "cinema"]

 query_classifier = TransformersQueryClassifier(
     model_name_or_path="typeform/distilbert-base-uncased-mnli",
     use_gpu=True,
     task="zero-shot-classification",
     labels=labels,
 )
 ```

Here the `labels` variable defines which labels you want the QueryClassifier to use. The model you pick should be a natural language inference model such as those trained on [the Multi-Genre Natural Language Inference (MultiNLI)](https://huggingface.co/datasets/multi_nli) dataset.

To perform the classification, run:

 ```python
 queries = [
     "In which films does John Travolta appear?",  # query about cinema
     "What is the Rolling Stones first album?",  # query about music
     "Who was Sergio Leone?",  # query about cinema
 ]

 import pandas as pd

 query_classification_results = {"Query": [], "Output Branch": [], "Class": []}

 for query in queries:
     result = query_classifier.run(query=query)
     query_classification_results["Query"].append(query)
     query_classification_results["Output Branch"].append(result[1])
     query_classification_results["Class"].append("music" if result[1] == "output_1" else "cinema")

 pd.DataFrame.from_dict(query_classification_results)
 ```

XXXXX MIGRATE AND COLLAPSE



### Questions

In such queries, users ask a question in a complete, grammatical sentence.
A Query Classifier can classify a query regardless of whether it ends with a question mark or not. Examples of questions:

*   who is the father of arya stark?
*   which country was jon snow filmed in
*   who are the younger brothers of arya stark?

### Statements

This type of query is a declarative sentence, such as:

*   Arya stark was a daughter of a lord.
*   Show countries that Jon snow was filmed in.
*   List all brothers of Arya.
